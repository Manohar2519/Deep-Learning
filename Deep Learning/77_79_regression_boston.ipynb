{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "from tensorflow.keras.datasets import boston_housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you use dataset.loaddata() : By default the data is split into 80 % and 20% randomly\n",
    "# and it will return 2 tuples\n",
    "# tuple 1  X_train , y_train (80 % of the data)\n",
    "#tuple 2 X_test , y_test (20 % of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(features, prices ), _  = boston_housing.load_data(test_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of examples: 506\n"
     ]
    }
   ],
   "source": [
    "print(\"No of examples:\",features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of columns 13\n"
     ]
    }
   ],
   "source": [
    "print(\"no of columns\",features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1      2    3      4      5      6       7     8      9    10  \\\n",
       "0  1.23247   0.0   8.14  0.0  0.538  6.142   91.7  3.9769   4.0  307.0  21.0   \n",
       "1  0.02177  82.5   2.03  0.0  0.415  7.610   15.7  6.2700   2.0  348.0  14.7   \n",
       "2  4.89822   0.0  18.10  0.0  0.631  4.970  100.0  1.3325  24.0  666.0  20.2   \n",
       "3  0.03961   0.0   5.19  0.0  0.515  6.037   34.5  5.9853   5.0  224.0  20.2   \n",
       "4  3.69311   0.0  18.10  0.0  0.713  6.376   88.4  2.5671  24.0  666.0  20.2   \n",
       "\n",
       "       11     12  \n",
       "0  396.90  18.72  \n",
       "1  395.38   3.11  \n",
       "2  375.52   3.26  \n",
       "3  396.90   8.01  \n",
       "4  391.43  14.65  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- My dataset contains 506 rows and 13 columns and I am trying to predict a house price based on the independent variables.\n",
    "\n",
    "- how many neurons in my input layer - ?  ( 13) \n",
    "\n",
    "- what is the loss function -?  ( mean squared ) \n",
    "\n",
    "- how many neurons in my last layer -?  (1)\n",
    "\n",
    "- Sequential API\n",
    "\n",
    "- when we did our playground, is it not sequential? we had our input layer then we added one hidden layer and one hidden layer and last layer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API\n",
    "- Sequence is a linear stack of layers\n",
    "- The model should know what input shape it is taking\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization , Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(5,input_shape=(13,))) #input layer with 13 neurons and 10 neurons on hidden\n",
    "model.add(Dense(1)) #prediction layer\n",
    "model.compile(optimizer=\"sgd\",loss=\"mse\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9a14b5aa90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features,prices,epochs=100,validation_split=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dense is a keyword that represents a fully connected layer\n",
    "# model.add(BatchNormalization(input_shape=(13,)))\n",
    "# model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd  = Stociastic gradient descent\n",
    "#mse = mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 260.3403 - val_loss: 210.2843\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.9502 - val_loss: 105.9042\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 50.0637 - val_loss: 107.6365\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 52.6773 - val_loss: 486.2982\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 35.1120 - val_loss: 327.6465\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 37.4038 - val_loss: 101.3918\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.3483 - val_loss: 79.4592\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.5949 - val_loss: 31.7630\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.1658 - val_loss: 83.1333\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.2314 - val_loss: 23.7197\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.0771 - val_loss: 167.1964\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 44.1627 - val_loss: 29.0103\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.6610 - val_loss: 98.9699\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9963 - val_loss: 91.8394\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 40.7603 - val_loss: 69.2274\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 35.8577 - val_loss: 137.4504\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 40.3291 - val_loss: 41.9281\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.5935 - val_loss: 35.9238\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.0482 - val_loss: 55.9373\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.9748 - val_loss: 35.4425\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.5073 - val_loss: 191.0987\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 49.4818 - val_loss: 54.1691\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.2051 - val_loss: 35.7985\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.9791 - val_loss: 30.2696\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.5610 - val_loss: 209.8212\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 42.9329 - val_loss: 52.4961\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.1406 - val_loss: 34.4869\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.6745 - val_loss: 110.2800\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 38.1275 - val_loss: 28.3297\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.7694 - val_loss: 43.1280\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.5382 - val_loss: 40.3213\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 28.9702 - val_loss: 33.5306\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.9669 - val_loss: 64.3017\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 35.0941 - val_loss: 34.7306\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.3186 - val_loss: 35.4539\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.6493 - val_loss: 52.4260\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.6052 - val_loss: 26.6806\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.8953 - val_loss: 60.3852\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 36.9634 - val_loss: 157.5916\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 48.4193 - val_loss: 32.8141\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.8537 - val_loss: 56.8932\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.5526 - val_loss: 63.4960\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.9408 - val_loss: 42.9440\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.7232 - val_loss: 54.2472\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.4265 - val_loss: 29.6230\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 25.6669 - val_loss: 50.9398\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.6045 - val_loss: 23.9885\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.4721 - val_loss: 188.9552\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 48.2387 - val_loss: 28.8158\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 30.9512 - val_loss: 27.0140\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 31.8473 - val_loss: 27.7503\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.1126 - val_loss: 69.1540\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2476 - val_loss: 33.5293\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.9944 - val_loss: 46.6503\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.6707 - val_loss: 35.8480\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 27.8885 - val_loss: 25.2108\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 28.7317 - val_loss: 40.2581\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.3587 - val_loss: 33.2565\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.2596 - val_loss: 145.5217\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 42.2161 - val_loss: 25.1933\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.0926 - val_loss: 71.1678\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.7286 - val_loss: 85.3308\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 35.7052 - val_loss: 25.5735\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.6258 - val_loss: 161.4682\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 49.0270 - val_loss: 41.3226\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.0621 - val_loss: 34.7035\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.9587 - val_loss: 148.7760\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.4712 - val_loss: 28.2487\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.9473 - val_loss: 41.8721\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.7659 - val_loss: 37.5570\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.2991 - val_loss: 24.9504\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.5781 - val_loss: 29.0936\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.8086 - val_loss: 26.4733\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.5912 - val_loss: 29.3875\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.3863 - val_loss: 26.7643\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.7251 - val_loss: 43.2757\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.6551 - val_loss: 40.4803\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.4708 - val_loss: 37.6896\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.8629 - val_loss: 51.8780\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 37.0746 - val_loss: 36.1940\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 31.8443 - val_loss: 44.2939\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.5073 - val_loss: 108.0843\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.0788 - val_loss: 42.5816\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.6545 - val_loss: 29.1259\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.3099 - val_loss: 44.6113\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.7082 - val_loss: 29.1503\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.4824 - val_loss: 80.1526\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.5035 - val_loss: 29.2445\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.0750 - val_loss: 28.4652\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.8963 - val_loss: 94.3354\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.9683 - val_loss: 199.7988\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 47.5479 - val_loss: 29.9762\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.3959 - val_loss: 29.4687\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.4891 - val_loss: 28.9527\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.5173 - val_loss: 126.2554\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 36.4578 - val_loss: 23.7022\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 25.7311 - val_loss: 38.2764\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.2033 - val_loss: 24.6861\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.6204 - val_loss: 25.2834\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.5303 - val_loss: 32.8679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9a175b8760>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
