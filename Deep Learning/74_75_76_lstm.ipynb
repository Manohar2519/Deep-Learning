{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding,LSTM,SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I_Am_Kenzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PeacefulQuest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PussssyCroook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MattFromTexas31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sharonDay5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  ...  tweet_location               user_timezone\n",
       "0   1  No candidate mentioned  ...             NaN                       Quito\n",
       "1   2            Scott Walker  ...             NaN                         NaN\n",
       "2   3  No candidate mentioned  ...             NaN                         NaN\n",
       "3   4  No candidate mentioned  ...           Texas  Central Time (US & Canada)\n",
       "4   5            Donald Trump  ...             NaN                     Arizona\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data\n",
    "data = pd.read_csv('Sentiment.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value of target 3\n",
      "value counts of target Negative    8493\n",
      "Neutral     3142\n",
      "Positive    2236\n",
      "Name: sentiment, dtype: int64\n",
      "(2236, 2)\n",
      "(8493, 2)\n",
      "                                                text sentiment\n",
      "0    scottwalker didnt catch the full gopdebate l...  Positive\n",
      "1    robgeorge that carly fiorina is trending  ho...  Positive\n",
      "2    danscavino gopdebate w realdonaldtrump deliv...  Positive\n",
      "3    gregabbott_tx tedcruz on my first day i will...  Positive\n",
      "4    warriorwoman91 i liked her and was happy whe...  Negative\n"
     ]
    }
   ],
   "source": [
    "#lets take the relevant information\n",
    "data = data [['text','sentiment']]\n",
    "print(\"Unique value of target\",data.sentiment.nunique())\n",
    "print(\"value counts of target\",data.sentiment.value_counts())\n",
    "\n",
    "### Preprocessing ####\n",
    "# Removing the neutral tweets and resetting the index\n",
    "data = data[data.sentiment!=\"Neutral\"]\n",
    "data.reset_index(inplace=True)\n",
    "data.drop(['index'],axis=1,inplace=True)\n",
    "#make the data lower case\n",
    "#remove characters which are not alphabets\n",
    "data['text'] = data['text'].apply(lambda x : x.lower())\n",
    "data['text']=data['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
    "print(data[data.sentiment=='Positive'].shape)\n",
    "print(data[data.sentiment=='Negative'].shape)\n",
    "#lets remove the rt from the statements\n",
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace(\"rt\",\" \")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "tokenizer = Tokenizer(num_words=max_features,split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will use LSTM network,  the embedding dimension, lstm_out , batch_size, dropout all these values are hyper parameters so we need to play around with these values for efficient algorithm.\n",
    "- we will use softmax and categorical cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 28, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 400)               846400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 802       \n",
      "=================================================================\n",
      "Total params: 1,103,202\n",
      "Trainable params: 1,103,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 400\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,embed_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7510, 28) (7510, 2)\n",
      "(3219, 28) (3219, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=2)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "235/235 [==============================] - 44s 187ms/step - loss: 0.4331 - accuracy: 0.8178\n",
      "Epoch 2/15\n",
      "235/235 [==============================] - 45s 193ms/step - loss: 0.3172 - accuracy: 0.8688\n",
      "Epoch 3/15\n",
      "235/235 [==============================] - 46s 195ms/step - loss: 0.2745 - accuracy: 0.8838\n",
      "Epoch 4/15\n",
      "235/235 [==============================] - 46s 194ms/step - loss: 0.2451 - accuracy: 0.9028\n",
      "Epoch 5/15\n",
      "235/235 [==============================] - 47s 198ms/step - loss: 0.2177 - accuracy: 0.9132\n",
      "Epoch 6/15\n",
      "235/235 [==============================] - 43s 182ms/step - loss: 0.1953 - accuracy: 0.9221\n",
      "Epoch 7/15\n",
      "235/235 [==============================] - 46s 195ms/step - loss: 0.1748 - accuracy: 0.9313\n",
      "Epoch 8/15\n",
      "235/235 [==============================] - 46s 197ms/step - loss: 0.1527 - accuracy: 0.9381\n",
      "Epoch 9/15\n",
      "235/235 [==============================] - 47s 200ms/step - loss: 0.1361 - accuracy: 0.9437\n",
      "Epoch 10/15\n",
      "235/235 [==============================] - 47s 202ms/step - loss: 0.1318 - accuracy: 0.9463\n",
      "Epoch 11/15\n",
      "235/235 [==============================] - 53s 227ms/step - loss: 0.1207 - accuracy: 0.9502\n",
      "Epoch 12/15\n",
      "235/235 [==============================] - 51s 217ms/step - loss: 0.1162 - accuracy: 0.9533\n",
      "Epoch 13/15\n",
      "235/235 [==============================] - 53s 224ms/step - loss: 0.1121 - accuracy: 0.9527\n",
      "Epoch 14/15\n",
      "235/235 [==============================] - 52s 222ms/step - loss: 0.1006 - accuracy: 0.9582\n",
      "Epoch 15/15\n",
      "235/235 [==============================] - 52s 223ms/step - loss: 0.1007 - accuracy: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fca2c240400>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train,y_train,epochs=15,batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 4s 38ms/step - loss: 0.7894 - accuracy: 0.8251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7893904447555542, 0.8251009583473206]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = pd.get_dummies(test_preds).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      2522\n",
      "           1       0.61      0.55      0.58       697\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      3219\n",
      "   macro avg       0.74      0.73      0.73      3219\n",
      "weighted avg       0.82      0.83      0.82      3219\n",
      " samples avg       0.83      0.83      0.83      3219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
